{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Overview the file structure:"
      ],
      "metadata": {
        "id": "lu6j_Q2gF1mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "\n",
        "def inspect_tflite_model(model_path):\n",
        "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "    tensor_details = interpreter.get_tensor_details()\n",
        "    ops = interpreter._get_ops_details()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(f\"Model Inspection: {model_path}\")\n",
        "    print(\"=\"*50 + \"\\n\")\n",
        "\n",
        "    # 1. Print Input/Output Details\n",
        "    print(\"\\n[Input Tensors]\")\n",
        "    input_table = []\n",
        "    for i, detail in enumerate(input_details):\n",
        "        input_table.append([\n",
        "            i, detail['name'], detail['shape'], detail['dtype'],\n",
        "            detail.get('quantization', 'N/A')\n",
        "        ])\n",
        "    print(tabulate(input_table, headers=[\"Index\", \"Name\", \"Shape\", \"DType\", \"Quantization\"]))\n",
        "\n",
        "    print(\"\\n[Output Tensors]\")\n",
        "    output_table = []\n",
        "    for i, detail in enumerate(output_details):\n",
        "        output_table.append([\n",
        "            i, detail['name'], detail['shape'], detail['dtype'],\n",
        "            detail.get('quantization', 'N/A')\n",
        "        ])\n",
        "    print(tabulate(output_table, headers=[\"Index\", \"Name\", \"Shape\", \"DType\", \"Quantization\"]))\n",
        "\n",
        "    print(\"\\n[All Tensors]\")\n",
        "    tensor_table = []\n",
        "    for tensor in tensor_details:\n",
        "        tensor_table.append([\n",
        "            tensor['index'], tensor['name'], tensor['shape'], tensor['dtype'],\n",
        "            tensor.get('quantization', 'N/A'), tensor.get('sparsity_parameters', 'N/A')\n",
        "        ])\n",
        "    print(tabulate(tensor_table, headers=[\"Index\", \"Name\", \"Shape\", \"DType\", \"Quantization\", \"Sparsity\"]))\n",
        "\n",
        "    print(\"\\n[Operations]\")\n",
        "    ops_table = []\n",
        "    for op in ops:\n",
        "        ops_table.append([\n",
        "            op['index'], op['op_name'], op['inputs'], op['outputs']\n",
        "        ])\n",
        "    print(tabulate(ops_table, headers=[\"Index\", \"Op Name\", \"Inputs\", \"Outputs\"]))\n",
        "\n",
        "    print(\"\\n[Model Summary]\")\n",
        "    print(f\"- Inputs: {len(input_details)}\")\n",
        "    print(f\"- Outputs: {len(output_details)}\")\n",
        "    print(f\"- Tensors: {len(tensor_details)}\")\n",
        "    print(f\"- Operations: {len(ops)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model_path = \"d-vector-extractor-256.tflite\"\n",
        "    inspect_tflite_model(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdgkJ3AXFZwy",
        "outputId": "5f06a7b1-1adc-46be-8e21-8003b25fec8a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==================================================\n",
            "Model Inspection: d-vector-extractor-256.tflite\n",
            "==================================================\n",
            "\n",
            "\n",
            "[Input Tensors]\n",
            "  Index  Name                     Shape          DType                    Quantization\n",
            "-------  -----------------------  -------------  -----------------------  --------------\n",
            "      0  serving_default_input:0  [ 1 40 40  1]  <class 'numpy.float32'>  (0.0, 0)\n",
            "\n",
            "[Output Tensors]\n",
            "  Index  Name                         Shape      DType                    Quantization\n",
            "-------  ---------------------------  ---------  -----------------------  --------------\n",
            "      0  StatefulPartitionedCall_1:0  [  1 256]  <class 'numpy.float32'>  (0.0, 0)\n",
            "\n",
            "[All Tensors]\n",
            "  Index  Name                                                                                                                                                                              Shape          DType                    Quantization    Sparsity\n",
            "-------  --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -------------  -----------------------  --------------  ----------\n",
            "      0  serving_default_input:0                                                                                                                                                           [ 1 40 40  1]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      1  arith.constant                                                                                                                                                                    [64]           <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      2  arith.constant1                                                                                                                                                                   [32]           <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      3  arith.constant2                                                                                                                                                                   [16]           <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      4  arith.constant3                                                                                                                                                                   [8]            <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      5  arith.constant4                                                                                                                                                                   [64  3  3 32]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      6  arith.constant5                                                                                                                                                                   [32  3  3 16]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      7  arith.constant6                                                                                                                                                                   [16  3  3  8]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      8  arith.constant7                                                                                                                                                                   [8 3 3 1]      <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "      9  arith.constant8                                                                                                                                                                   [2]            <class 'numpy.int32'>    (0.0, 0)        {}\n",
            "     10  d-vector-extractor-256_1/batch_normalization_1/batchnorm/mul                                                                                                                      [1]            <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     11  d-vector-extractor-256_1/batch_normalization_1/batchnorm/sub                                                                                                                      [1]            <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     12  d-vector-extractor-256_1/batch_normalization_1/batchnorm/mul_1                                                                                                                    [ 1 40 40  1]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     13  d-vector-extractor-256_1/batch_normalization_1/batchnorm/add_1                                                                                                                    [ 1 40 40  1]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     14  d-vector-extractor-256_1/conv2d_1/Relu;d-vector-extractor-256_1/conv2d_1/BiasAdd;d-vector-extractor-256_1/conv2d_1/convolution;d-vector-extractor-256_1/conv2d_1/Squeeze          [ 1 40 40  8]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     15  d-vector-extractor-256_1/max_pooling2d_1/MaxPool2d                                                                                                                                [ 1 13 13  8]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     16  d-vector-extractor-256_1/conv2d_1_2/Relu;d-vector-extractor-256_1/conv2d_1_2/BiasAdd;d-vector-extractor-256_1/conv2d_1_2/convolution;d-vector-extractor-256_1/conv2d_1_2/Squeeze  [ 1 13 13 16]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     17  d-vector-extractor-256_1/max_pooling2d_1_2/MaxPool2d                                                                                                                              [ 1  6  6 16]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     18  d-vector-extractor-256_1/conv2d_2_1/Relu;d-vector-extractor-256_1/conv2d_2_1/BiasAdd;d-vector-extractor-256_1/conv2d_2_1/convolution;d-vector-extractor-256_1/conv2d_2_1/Squeeze  [ 1  3  3 32]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     19  d-vector-extractor-256_1/conv2d_3_1/Relu;d-vector-extractor-256_1/conv2d_3_1/BiasAdd;d-vector-extractor-256_1/conv2d_3_1/convolution;d-vector-extractor-256_1/conv2d_3_1/Squeeze  [ 1  2  2 64]  <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "     20  StatefulPartitionedCall_1:0                                                                                                                                                       [  1 256]      <class 'numpy.float32'>  (0.0, 0)        {}\n",
            "\n",
            "[Operations]\n",
            "  Index  Op Name      Inputs                                   Outputs\n",
            "-------  -----------  -------------------------------------  ---------\n",
            "      0  MUL          [ 0 10]                                       12\n",
            "      1  ADD          [12 11]                                       13\n",
            "      2  CONV_2D      [13  8  4]                                    14\n",
            "      3  MAX_POOL_2D  [14]                                          15\n",
            "      4  CONV_2D      [15  7  3]                                    16\n",
            "      5  MAX_POOL_2D  [16]                                          17\n",
            "      6  CONV_2D      [17  6  2]                                    18\n",
            "      7  CONV_2D      [18  5  1]                                    19\n",
            "      8  RESHAPE      [19  9]                                       20\n",
            "      9  DELEGATE     [ 0  1  2  3  4  5  6  7  8  9 10 11]         20\n",
            "\n",
            "[Model Summary]\n",
            "- Inputs: 1\n",
            "- Outputs: 1\n",
            "- Tensors: 21\n",
            "- Operations: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to extract .npy files for each tensor according to the model previously generated"
      ],
      "metadata": {
        "id": "vhkHGFKnJDb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "model_path = 'd-vector-extractor-256.tflite'\n",
        "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "output_dir = \"tflite_tensors\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "tensor_details = interpreter.get_tensor_details()\n",
        "\n",
        "for tensor in tensor_details:\n",
        "    try:\n",
        "        if interpreter.get_tensor(tensor['index']).size == 0:\n",
        "            print(f\"Skipping empty tensor: {tensor['name']} (index {tensor['index']})\")\n",
        "            continue\n",
        "\n",
        "        tensor_data = interpreter.get_tensor(tensor['index'])\n",
        "        tensor_name = tensor['name'].replace('/', '_')\n",
        "\n",
        "        filename = f\"tensor_{tensor['index']:03d}_{tensor_name}_shape-{tensor['shape']}_dtype-{tensor['dtype']}.npy\"\n",
        "        np.save(os.path.join(output_dir, filename), tensor_data)\n",
        "        print(f\"Saved: {filename}\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"Failed to extract {tensor['name']} (index {tensor['index']}): {str(e)}\")\n",
        "        continue\n",
        "\n",
        "print(f\"\\nExtraction complete. Output directory: {output_dir}/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO17silIJC29",
        "outputId": "0e5a4ef0-8f8c-4036-84da-90dc5234c0b4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved: tensor_000_serving_default_input:0_shape-[ 1 40 40  1]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_001_arith.constant_shape-[64]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_002_arith.constant1_shape-[32]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_003_arith.constant2_shape-[16]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_004_arith.constant3_shape-[8]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_005_arith.constant4_shape-[64  3  3 32]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_006_arith.constant5_shape-[32  3  3 16]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_007_arith.constant6_shape-[16  3  3  8]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_008_arith.constant7_shape-[8 3 3 1]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_009_arith.constant8_shape-[2]_dtype-<class 'numpy.int32'>.npy\n",
            "Saved: tensor_010_d-vector-extractor-256_1_batch_normalization_1_batchnorm_mul_shape-[1]_dtype-<class 'numpy.float32'>.npy\n",
            "Saved: tensor_011_d-vector-extractor-256_1_batch_normalization_1_batchnorm_sub_shape-[1]_dtype-<class 'numpy.float32'>.npy\n",
            "Failed to extract d-vector-extractor-256_1/batch_normalization_1/batchnorm/mul_1 (index 12): Tensor data is null. Run allocate_tensors() first\n",
            "Failed to extract d-vector-extractor-256_1/batch_normalization_1/batchnorm/add_1 (index 13): Tensor data is null. Run allocate_tensors() first\n",
            "Failed to extract d-vector-extractor-256_1/conv2d_1/Relu;d-vector-extractor-256_1/conv2d_1/BiasAdd;d-vector-extractor-256_1/conv2d_1/convolution;d-vector-extractor-256_1/conv2d_1/Squeeze (index 14): Tensor data is null. Run allocate_tensors() first\n",
            "Failed to extract d-vector-extractor-256_1/max_pooling2d_1/MaxPool2d (index 15): Tensor data is null. Run allocate_tensors() first\n",
            "Failed to extract d-vector-extractor-256_1/conv2d_1_2/Relu;d-vector-extractor-256_1/conv2d_1_2/BiasAdd;d-vector-extractor-256_1/conv2d_1_2/convolution;d-vector-extractor-256_1/conv2d_1_2/Squeeze (index 16): Tensor data is null. Run allocate_tensors() first\n",
            "Failed to extract d-vector-extractor-256_1/max_pooling2d_1_2/MaxPool2d (index 17): Tensor data is null. Run allocate_tensors() first\n",
            "Failed to extract d-vector-extractor-256_1/conv2d_2_1/Relu;d-vector-extractor-256_1/conv2d_2_1/BiasAdd;d-vector-extractor-256_1/conv2d_2_1/convolution;d-vector-extractor-256_1/conv2d_2_1/Squeeze (index 18): Tensor data is null. Run allocate_tensors() first\n",
            "Failed to extract d-vector-extractor-256_1/conv2d_3_1/Relu;d-vector-extractor-256_1/conv2d_3_1/BiasAdd;d-vector-extractor-256_1/conv2d_3_1/convolution;d-vector-extractor-256_1/conv2d_3_1/Squeeze (index 19): Tensor data is null. Run allocate_tensors() first\n",
            "Saved: tensor_020_StatefulPartitionedCall_1:0_shape-[  1 256]_dtype-<class 'numpy.float32'>.npy\n",
            "\n",
            "Extraction complete. Output directory: tflite_tensors/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code to verify content of .npy files generated:"
      ],
      "metadata": {
        "id": "BNpsZbF4FSla"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV36jR-2E8Wd",
        "outputId": "98424514-edc9-4e86-a1d2-144b4ed0350e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 13 .npy files in tflite_tensors:\n",
            "\n",
            "tensor_000_serving_default_input:0_shape-[ 1 40 40  1]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (1, 40, 40, 1)\n",
            "  - Dtype: float32\n",
            "  - Min: -2408881504095047458328936448.0000, Max: 501704745483963226652672.0000, Mean: -3009670458895549645979648.0000\n",
            "  - Size: 1600 elements\n",
            "\n",
            "tensor_001_arith.constant_shape-[64]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (64,)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.4863, Max: 0.6305, Mean: -0.0099\n",
            "  - Size: 64 elements\n",
            "\n",
            "tensor_002_arith.constant1_shape-[32]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (32,)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.9408, Max: 0.5785, Mean: -0.0547\n",
            "  - Size: 32 elements\n",
            "\n",
            "tensor_003_arith.constant2_shape-[16]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (16,)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.7575, Max: 0.4480, Mean: -0.1527\n",
            "  - Size: 16 elements\n",
            "\n",
            "tensor_004_arith.constant3_shape-[8]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (8,)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.4341, Max: 0.7258, Mean: 0.1544\n",
            "  - Size: 8 elements\n",
            "\n",
            "tensor_005_arith.constant4_shape-[64  3  3 32]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (64, 3, 3, 32)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.9257, Max: 0.6105, Mean: 0.0007\n",
            "  - Size: 18432 elements\n",
            "\n",
            "tensor_006_arith.constant5_shape-[32  3  3 16]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (32, 3, 3, 16)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.7225, Max: 0.6194, Mean: 0.0054\n",
            "  - Size: 4608 elements\n",
            "\n",
            "tensor_007_arith.constant6_shape-[16  3  3  8]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (16, 3, 3, 8)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.6357, Max: 0.9199, Mean: 0.0211\n",
            "  - Size: 1152 elements\n",
            "\n",
            "tensor_008_arith.constant7_shape-[8 3 3 1]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (8, 3, 3, 1)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.9610, Max: 0.8763, Mean: -0.0139\n",
            "  - Size: 72 elements\n",
            "\n",
            "tensor_009_arith.constant8_shape-[2]_dtype-<class 'numpy.int32'>.npy:\n",
            "  - Shape: (2,)\n",
            "  - Dtype: int32\n",
            "  - Min: -1.0000, Max: 256.0000, Mean: 127.5000\n",
            "  - Size: 2 elements\n",
            "\n",
            "tensor_010_d-vector-extractor-256_1_batch_normalization_1_batchnorm_mul_shape-[1]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (1,)\n",
            "  - Dtype: float32\n",
            "  - Min: 67.1355, Max: 67.1355, Mean: 67.1355\n",
            "  - Size: 1 elements\n",
            "\n",
            "tensor_011_d-vector-extractor-256_1_batch_normalization_1_batchnorm_sub_shape-[1]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (1,)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.9282, Max: -0.9282, Mean: -0.9282\n",
            "  - Size: 1 elements\n",
            "\n",
            "tensor_020_StatefulPartitionedCall_1:0_shape-[  1 256]_dtype-<class 'numpy.float32'>.npy:\n",
            "  - Shape: (1, 256)\n",
            "  - Dtype: float32\n",
            "  - Min: -0.0000, Max: 0.0000, Mean: -0.0000\n",
            "  - Size: 256 elements\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def verify_npy_files(directory=\"tflite_tensors\"):\n",
        "    \"\"\"Verify contents of .npy files in a directory.\"\"\"\n",
        "    npy_files = [f for f in os.listdir(directory) if f.endswith('.npy')]\n",
        "\n",
        "    if not npy_files:\n",
        "        print(f\"No .npy files found in {directory}!\")\n",
        "        return\n",
        "\n",
        "    print(f\"Found {len(npy_files)} .npy files in {directory}:\\n\")\n",
        "\n",
        "    for file in sorted(npy_files):\n",
        "        filepath = os.path.join(directory, file)\n",
        "        data = np.load(filepath)\n",
        "\n",
        "        print(f\"{file}:\")\n",
        "        print(f\"  - Shape: {data.shape}\")\n",
        "        print(f\"  - Dtype: {data.dtype}\")\n",
        "        print(f\"  - Min: {np.min(data):.4f}, Max: {np.max(data):.4f}, Mean: {np.mean(data):.4f}\")\n",
        "        print(f\"  - Size: {data.size} elements\\n\")\n",
        "\n",
        "        if len(data.shape) == 4 and 'conv' in file.lower():\n",
        "            print(\"  Visualizing first filter of 4D weights...\")\n",
        "            plt.figure(figsize=(3, 3))\n",
        "            plt.imshow(data[0, :, :, 0], cmap='viridis')\n",
        "            plt.colorbar()\n",
        "            plt.title(f\"{file} (first filter)\")\n",
        "            plt.show()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    verify_npy_files()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deployment of header file of d_vector_extractor.h"
      ],
      "metadata": {
        "id": "Mh8eZw1tLMLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def sanitize_name(name):\n",
        "    \"\"\"Convert tensor names to valid C identifiers.\"\"\"\n",
        "    return name.replace('/', '_').replace(';', '_').replace(':', '_')\n",
        "\n",
        "def estimate_name(name):\n",
        "  match name:\n",
        "    case \"serving_default_input_0\":\n",
        "        return \"default_input\"\n",
        "    case \"arith.constant\":\n",
        "        return \"conv_4_BiasAdd_ReadVariableOp\"\n",
        "    case \"arith.constant1\":\n",
        "        return \"conv_3_BiasAdd_ReadVariableOp\"\n",
        "    case \"arith.constant2\":\n",
        "        return \"conv_2_BiasAdd_ReadVariableOp\"\n",
        "    case \"arith.constant3\":\n",
        "        return \"conv_1_BiasAdd_ReadVariableOp\"\n",
        "    case \"arith.constant4\":\n",
        "        return \"conv_4_Weights\"\n",
        "    case \"arith.constant5\":\n",
        "        return \"conv_3_Weights\"\n",
        "    case \"arith.constant6\":\n",
        "        return \"conv_2_Weights\"\n",
        "    case \"arith.constant7\":\n",
        "        return \"conv_1_Weights\"\n",
        "    case \"arith.constant8\":\n",
        "        return \"reshape_Dimensions\"\n",
        "    case \"d-vector-extractor-256_1_batch_normalization_1_batchnorm_mul\":\n",
        "        return \"batch_norm_mul\"\n",
        "    case \"d-vector-extractor-256_1_batch_normalization_1_batchnorm_sub\":\n",
        "        return \"batch_norm_sub\"\n",
        "\n",
        "def generate_header(npy_dir=\"tflite_tensors\", output_file=\"d_vector_extractor.h\"):\n",
        "    \"\"\"Generate a C header from .npy files.\"\"\"\n",
        "    npy_files = [f for f in os.listdir(npy_dir) if f.endswith('.npy')]\n",
        "\n",
        "    with open(output_file, \"w\") as f:\n",
        "        f.write(\"#ifndef D_VECTOR_EXTRACTOR_H\\n\")\n",
        "        f.write(\"#define D_VECTOR_EXTRACTOR_H\\n\\n\")\n",
        "\n",
        "        for file in sorted(npy_files):\n",
        "            data = np.load(os.path.join(npy_dir, file))\n",
        "            if data.size == 0:\n",
        "                continue\n",
        "\n",
        "            tensor_name = \"_\".join(file.split('_')[2:-2])\n",
        "            c_name = sanitize_name(tensor_name)\n",
        "            c_name = estimate_name(c_name)\n",
        "            f.write(f\"static const float {c_name}[{data.size}] = {{\\n\")\n",
        "\n",
        "            flat_data = data.flatten()\n",
        "            for i in range(0, len(flat_data), 8):\n",
        "                line = \", \".join(f\"{x:.6f}f\" for x in flat_data[i:i+8])\n",
        "                f.write(f\"    {line},\\n\")\n",
        "\n",
        "            f.write(\"};\\n\\n\")\n",
        "            f.write(f\"// Shape: {data.shape}\\n\\n\")\n",
        "        f.write(\"#endif // D_VECTOR_EXTRACTOR_H\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_header()"
      ],
      "metadata": {
        "id": "qkUMtwB8LRVW"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}